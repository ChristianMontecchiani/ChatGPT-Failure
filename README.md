# ChatGPT-Failure

ChatGPT is a Large Language Model and it is highly capable with respect to the other public chatbots. However, this system presents different problems that can be categorized in the following list:

1. [Reasoning](#1-reasoning)
2. [Factuality](#2-factuality)
3. [Bias](#3-bias)
4. [Age Risk](#4-age-risk)
5. [Abstraction](#5-abstraction)
6. [Emotional Limitation](#6-emotional-limitation)


## 1. Reasoning
Critical thinking, decision making, and problem solving are all crucila activities that rely heavily on the fundamental aspect of human intellingece known as **reasoning**. Models like ChatGPT lack a _world model_, meaning they do not possess a complete understanding of the physical and social world, or the capability to reason about the connections between concepts and entities, following a causality principle. Adapted from  [A Categorical Archive of ChatGPT Failures] 


## 2. Factuality

ChatGPT commits errors due to inaccuracies in information or sattementes that are not in accordance with reality or the truth.([A Categorical Archive of ChatGPT Failures])


## 3. Bias 

Bias in a language model refers to the systematic inaccuracies or stereotypes in the generated language output, which are influenced by the training data and reflect the societal and cultural prejudices that exist in that data. ([Investigating Gender Bias in Language Models Using Causal Mediation Analysis])

## 4. Age risk 

OpenAI does not have age controls to stop people under the age of 13 from using the text generation system. ([Wired Article])

## 5. Abstraction

ChatGPT still lacks the human ability to **abstract**. We as human have the ability to abstract representations and  manipulating symbols. Abstraction can facilitate reasoning, problem solving and learning across many domains. Adapted from ([Abstraction Article])

## 6. Emotional Limitation

The capability of understanding when a discussion becomes/is emotionally hurting for the person interacting with and it is modified/stopped accordingly.



[A Categorical Archive of ChatGPT Failures]: https://arxiv.org/abs/2302.03494

[Investigating Gender Bias in Language Models Using Causal Mediation Analysis]: https://proceedings.neurips.cc/paper/2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf

[Wired Article]: https://www.wired.com/story/italy-ban-chatgpt-privacy-gdpr/

[Abstraction Article]: https://royalsocietypublishing.org/doi/10.1098/rstb.2021.0361